{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import movie_reviews as mr      # taking nltk inbuilt dataset\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword= set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_raw= mr.raw(mr.fileids('pos'))       # raw positive sentences from corpus (unformated form)\n",
    "neg_raw= mr.raw(mr.fileids('neg'))       # raw negtive sentences from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos= pos_raw.split('\\n')              # splliting sentences from raw data file\n",
    "neg= pos_raw.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag= []       # giving each sentence label \n",
    "neg_tag= []\n",
    "for i in pos:\n",
    "    pos_tag.append([i,1])\n",
    "for i in neg:\n",
    "    neg_tag.append([i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos= pd.DataFrame(pos_tag,columns=['txt','status'])\n",
    "neg= pd.DataFrame(neg_tag,columns=['txt','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.concat([pos,neg],axis=0)          # creating processesable dataframe\n",
    "data=shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32938\n",
       "0    32938\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfid\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= tfid(stop_words= stopword,max_features=21)       # using TfIdf to make words as features by making word vectors\n",
    "x= vectorizer.fit_transform(data['txt'])\n",
    "y= data.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,random_state= 42)         # splitting data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4966238635292005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB        # using multiNomial Naive Bayes as classifier\n",
    "\n",
    "clf= MultinomialNB()\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "pred= clf.predict(x_test)\n",
    "print(roc_auc_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65876, 21)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.4951045347972237\n",
      "21 0.4966238635292005\n",
      "22 0.49416746519807087\n",
      "23 0.49510524278776513\n",
      "24 0.4934397185873044\n",
      "25 0.4942005374568356\n",
      "26 0.49182745136393036\n",
      "27 0.4922044015054945\n",
      "28 0.49339790097915387\n",
      "29 0.493979901834336\n",
      "30 0.4930821160074844\n",
      "31 0.49318418962573746\n",
      "32 0.49164338919925515\n",
      "33 0.4906535152544381\n",
      "34 0.48984682061218426\n",
      "35 0.49000221733765237\n",
      "36 0.4906749758821638\n",
      "37 0.48933792764931416\n",
      "38 0.4884977410255855\n",
      "39 0.4888862013813785\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,40):\n",
    "    vectorizer= tfid(stop_words= stopword,max_features=i)          # checking for optimum max features\n",
    "    x= vectorizer.fit_transform(data['txt'])\n",
    "    y= data.status\n",
    "    x_train,x_test,y_train,y_test= train_test_split(x,y,random_state= 42)\n",
    "    clf= MultinomialNB()\n",
    "    clf.fit(X=x_train,y=y_train)\n",
    "    pred= clf.predict(x_test)\n",
    "    print(i,roc_auc_score(pred,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus 21 is optimum no. of max features for this dataset and TfIdf takes most informative word by setting higher weights to unique words in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
